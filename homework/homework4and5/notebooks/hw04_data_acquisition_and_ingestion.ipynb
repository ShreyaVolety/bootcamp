{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83d458b",
   "metadata": {},
   "source": [
    "# Homework 4: Data Acquisition and Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a7ce8",
   "metadata": {},
   "source": [
    "## Task 1: API Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7731d08",
   "metadata": {},
   "source": [
    "Loading environment variables below.\n",
    "\n",
    "I've used the FMP API for the data below, with yfinance as fallback - this is because Alpha Advantage's Time series endpoint is not freely available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd90499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import yfinance\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "config_path = Path.cwd().parent / \"src\"\n",
    "sys.path.append(str(config_path))\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "\n",
    "load_env(env_path)\n",
    "\n",
    "try:\n",
    "    fmp_key = get_key(\"API_KEY\")\n",
    "    #print(f'''Loaded api key: {fmp_key}''')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'''Error retrieving key: {e} and yfinance will be used instead''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735f761",
   "metadata": {},
   "source": [
    "Below pulls raw data, and saves down 1 year's worth of adjusted close prices for the given ticker. It raises a flag if date/adjclose are not part of the response of the API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec51670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "use_api = bool(fmp_key)\n",
    "\n",
    "end_date, start_date = year_date_interval_creator()\n",
    "if use_api:\n",
    "\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}\"\n",
    "    params = {\n",
    "        \"apikey\": fmp_key,\n",
    "        \"from\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"to\": start_date.strftime(\"%Y-%m-%d\") \n",
    "    }\n",
    "    r = requests.get(url, params=params)\n",
    "    data = r.json()\n",
    "    historical = data.get(\"historical\", [])\n",
    "    key = [k for k in historical if \"adjClose\" in k.keys() or \"date\" in k.keys()]\n",
    "    assert key, f\"Unexpected response keys: {list (data.keys())}\"\n",
    "    df_raw_api = pd.DataFrame(historical)\n",
    "    df_raw_api['date'] = pd.to_datetime(df_raw_api['date'])\n",
    "    df_raw_api['adjClose']=pd.to_numeric(df_raw_api['adjClose'])\n",
    "    df_raw_api = df_raw_api[['date','adjClose']]\n",
    "\n",
    "else:\n",
    "\n",
    "    import yfinance as yf\n",
    "    df_raw_api = yf.download(ticker, period=\"1y\", interval=\"1d\",auto_adjust=True).reset_index()[[('Date',''), ('Close',ticker)]]\n",
    "    df_raw_api.columns = ['date','adjClose']\n",
    "    df_raw_api['date'] = pd.to_datetime(df_raw_api['date'])\n",
    "    df_raw_api['adjClose']=pd.to_numeric(df_raw_api['adjClose'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e015a",
   "metadata": {},
   "source": [
    "Data pulled is validated and saved using functions from the utils module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe0044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/svolety/Desktop/bootcamp IV/bootcamp/homework/homework4and5/data/raw/api_source-fmp_symbol-AAPL_20250818-094726.csv\n"
     ]
    }
   ],
   "source": [
    "msg_dict = validate_df(df_raw_api,['date','adjClose'],{'date':'datetime64[ns]','adjClose':'float64'})\n",
    "msg_dict\n",
    "\n",
    "fname = safe_filename(prefix=\"api\", meta={\"source\": \"fmp\" if use_api else \"yfinance\", \"symbol\": ticker})\n",
    "raw_data_path = Path.cwd().parent / \"data\" / \"raw\"\n",
    "out_path = raw_data_path / fname\n",
    "df_raw_api.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b4f411",
   "metadata": {},
   "source": [
    "## Task 2: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5be3e",
   "metadata": {},
   "source": [
    "Most websites with market data - yfinance/morningstar/fmp/alphaadvantage - either block requests or I need to use selenium to run the JS and pull data from the table. (otherwise it pulls a blank table) I'll return to this part of the assignment post lecture on Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239b86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a wikipedia table instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf20af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'na_total': 'Total NA values: 63'}\n",
      "Saved: /Users/svolety/Desktop/bootcamp IV/bootcamp/homework/homework4and5/data/raw/scrape_site-example_table-markets_20250818-094816.csv\n"
     ]
    }
   ],
   "source": [
    "SCRAPE_URL = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(PPP)_per_capita\"  # replace with permitted page\n",
    "headers = {\"User-Agent\": \"AFE-Course-Notebook/1.0 (contact: instructor@example.edu)\"}\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    table = soup.find_all('table')\n",
    "    second_table = table[1]\n",
    "    rows = []\n",
    "    for tr in second_table.find_all('tr'):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "    # assume first row is header\n",
    "    data = rows[2:]\n",
    "    df_scrape = pd.DataFrame(data, columns=['Country',*rows[1]])\n",
    "except Exception as e:\n",
    "    print(\"Scrape failed (demoing with inline HTML).\", e)\n",
    "    html = \"\"\"\n",
    "    <table>\n",
    "      <tr><th>Ticker</th><th>Price</th></tr>\n",
    "      <tr><td>AAA</td><td>101.2</td></tr>\n",
    "      <tr><td>BBB</td><td>98.7</td></tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rows = []\n",
    "    for tr in soup.find_all('tr'):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "    header, *data = rows\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "if 'Price' in df_scrape.columns:\n",
    "    df_scrape['Price'] = pd.to_numeric(df_scrape['Price'], errors='coerce')\n",
    "\n",
    "msgs2 = validate_df(df_scrape, required_cols=list(df_scrape.columns), dtypes_map={})\n",
    "print(msgs2)\n",
    "\n",
    "fname2 = safe_filename(prefix=\"scrape\", meta={\"site\": \"example\", \"table\": \"markets\"})\n",
    "out_path2 = Path.cwd().parent / \"data\" / \"raw\" / fname2\n",
    "df_scrape.to_csv(out_path2, index=False)\n",
    "print(\"Saved:\", out_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1975dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
